{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname\n",
    "from shutil import copyfile\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import sentencepiece as spm\n",
    "\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "from fairseq.tasks.translation import TranslationTask\n",
    "from fairseq.hub_utils import GeneratorHubInterface\n",
    "\n",
    "from transformers import WEIGHTS_NAME, logging\n",
    "from transformers.configuration_fsmt import FSMTConfig\n",
    "from transformers.modeling_fsmt import FSMTForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from da.hugging_fseq_tokenizer import HuggingFseqTokenizer\n",
    "from da.convert_fsmt_simple_checkpoint_to_pytorch import convert_fsmt_simple_checkpoint_to_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = \"experiments/concat\"\n",
    "fseq_checkpoint_path = f\"{exp_path}/checkpoint_best.pt\"\n",
    "save_dir = f\"{exp_path}/hf\"\n",
    "data_path = \"data-prep/bin-data-en-et-base/\"\n",
    "spm_model_file = \"data-prep/preproc-models/syscl-en-et.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to experiments/concat_base/hf\n",
      "Generating experiments/concat_base/hf/config.json\n",
      "Generating experiments/concat_base/hf/pytorch_model.bin\n",
      "Generating experiments/concat_base/hf/vocab.txt\n",
      "Conversion is done!\n"
     ]
    }
   ],
   "source": [
    "convert_fsmt_simple_checkpoint_to_pytorch(\n",
    "    fseq_checkpoint_path, \n",
    "    save_dir, \n",
    "    data_path, \n",
    "    spm_model_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_hf = HuggingFseqTokenizer.from_pretrained(save_dir)\n",
    "model_hf = FSMTForConditionalGeneration.from_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = [\"my name is Max.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer_hf.batch_encode_plus(\n",
    "    src,\n",
    "    padding=\"longest\", \n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch = model_hf.generate(**batch,\n",
    "                       return_dict=True,\n",
    "                       output_hidden_states=True,\n",
    "                       output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,  283, 1713,    9, 8570,    5,    2]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minu nimi on Max.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_hf.batch_decode(out_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = [\"my name is Max.\", \"my name is Alex.\", \"i go to school every day (no)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer_hf.batch_encode_plus(\n",
    "    src,\n",
    "    padding=\"longest\", \n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf.generate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch = model_hf.generate(**batch,\n",
    "                       return_dict=True,\n",
    "                       output_hidden_states=True,\n",
    "                       output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,   283,  1713,     9,  8570,     5,     2,     1,     1,     1,\n",
       "             1],\n",
       "        [    2,   283,  1713,     9, 12102,     5,     2,     1,     1,     1,\n",
       "             1],\n",
       "        [    2,    87,  3302,   138, 17849,   257,  2686,    16,  5682,    15,\n",
       "             2]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minu nimi on Max.<pad><pad><pad><pad>',\n",
       " 'minu nimi on Alex.<pad><pad><pad><pad>',\n",
       " 'Ma käin koolis iga päev (ei)']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_hf.batch_decode(out_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_batch = model_hf.forward(**batch,\n",
    "                       return_dict=True,\n",
    "                       output_hidden_states=True,\n",
    "                       output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'decoder_hidden_states', 'decoder_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_batch.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (da)",
   "language": "python",
   "name": "da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
