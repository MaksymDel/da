{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"da-corpora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cl-JRC-Acquis.en-et.docs.train\n",
      "cl-OpenSubtitles.en-et.docs.train\n",
      "cl-EMEA.en-et.docs.train\n",
      "cl-Europarl.en-et.docs.train\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "files = []\n",
    "os.chdir(data_path)\n",
    "for file in glob.glob(\"*.train\"):\n",
    "    print(file)\n",
    "    files.append(open(file, 'r').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce files to eglish sentences but keep doc ids\n",
    "\n",
    "sent_index = deepcopy(files)\n",
    "\n",
    "for ind, f in enumerate(files):\n",
    "    for i in range(len(f)):\n",
    "        sent_index[ind][i] = f[i].split('\\t')[0]\n",
    "        f[i] = f[i].split('\\t')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [line for file in files for line in file]\n",
    "sent_index = [line for file in sent_index for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sentences) == len(sent_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = sentences[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('xlm-roberta-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_value_of_dtype(dtype: torch.dtype):\n",
    "    if not dtype.is_floating_point:\n",
    "        raise TypeError(\"Only supports floating point dtypes.\")\n",
    "    if dtype == torch.float or dtype == torch.double:\n",
    "        return 1e-13\n",
    "    elif dtype == torch.half:\n",
    "        return 1e-4\n",
    "    else:\n",
    "        raise TypeError(\"Does not support dtype \" + str(dtype))\n",
    "        \n",
    "def masked_mean(\n",
    "    vector: torch.Tensor, mask: torch.BoolTensor, dim: int, keepdim: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \n",
    "    replaced_vector = vector.masked_fill(~mask, 0.0)\n",
    "\n",
    "    value_sum = torch.sum(replaced_vector, dim=dim, keepdim=keepdim)\n",
    "    value_count = torch.sum(mask, dim=dim, keepdim=keepdim)\n",
    "    return value_sum / value_count.float().clamp(min=tiny_value_of_dtype(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder:\n",
    "    def __init__(self, model, tokeinzer):    \n",
    "        self.model = model.cuda()\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def embed_batch(self, batch):\n",
    "        batch = self.tokenizer.batch_encode_plus(batch, \n",
    "                          return_tensors='pt', \n",
    "                          truncation=True, \n",
    "                          padding=True, \n",
    "                          max_length=100)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            res = self.model(\n",
    "                input_ids=batch.input_ids.cuda(),\n",
    "                attention_mask=batch.attention_mask.cuda(),\n",
    "                output_hidden_states=True, \n",
    "                return_dict=True\n",
    "            )\n",
    "            \n",
    "            hiddens = res['hidden_states'][7].cpu().detach()\n",
    "        \n",
    "        hiddens_sent = masked_mean(vector=hiddens, mask=batch.attention_mask.unsqueeze(2).bool(), dim=1)\n",
    "        return hiddens_sent.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1912\n",
      "1 / 1912\n",
      "2 / 1912\n",
      "3 / 1912\n",
      "4 / 1912\n",
      "5 / 1912\n",
      "6 / 1912\n",
      "7 / 1912\n",
      "8 / 1912\n",
      "9 / 1912\n",
      "10 / 1912\n",
      "11 / 1912\n",
      "12 / 1912\n",
      "13 / 1912\n",
      "14 / 1912\n",
      "15 / 1912\n",
      "16 / 1912\n",
      "17 / 1912\n",
      "18 / 1912\n",
      "19 / 1912\n",
      "20 / 1912\n",
      "21 / 1912\n",
      "22 / 1912\n",
      "23 / 1912\n",
      "24 / 1912\n",
      "25 / 1912\n",
      "26 / 1912\n",
      "27 / 1912\n",
      "28 / 1912\n",
      "29 / 1912\n",
      "30 / 1912\n",
      "31 / 1912\n",
      "32 / 1912\n",
      "33 / 1912\n",
      "34 / 1912\n",
      "35 / 1912\n",
      "36 / 1912\n",
      "37 / 1912\n",
      "38 / 1912\n",
      "39 / 1912\n",
      "40 / 1912\n",
      "41 / 1912\n",
      "42 / 1912\n",
      "43 / 1912\n",
      "44 / 1912\n",
      "45 / 1912\n",
      "46 / 1912\n",
      "47 / 1912\n",
      "48 / 1912\n",
      "49 / 1912\n",
      "50 / 1912\n",
      "51 / 1912\n",
      "52 / 1912\n",
      "53 / 1912\n",
      "54 / 1912\n",
      "55 / 1912\n",
      "56 / 1912\n",
      "57 / 1912\n",
      "58 / 1912\n",
      "59 / 1912\n",
      "60 / 1912\n",
      "61 / 1912\n",
      "62 / 1912\n",
      "63 / 1912\n",
      "64 / 1912\n",
      "65 / 1912\n",
      "66 / 1912\n",
      "67 / 1912\n",
      "68 / 1912\n",
      "69 / 1912\n",
      "70 / 1912\n",
      "71 / 1912\n",
      "72 / 1912\n",
      "73 / 1912\n",
      "74 / 1912\n",
      "75 / 1912\n",
      "76 / 1912\n",
      "77 / 1912\n",
      "78 / 1912\n",
      "79 / 1912\n",
      "80 / 1912\n",
      "81 / 1912\n",
      "82 / 1912\n",
      "83 / 1912\n",
      "84 / 1912\n",
      "85 / 1912\n",
      "86 / 1912\n",
      "87 / 1912\n",
      "88 / 1912\n",
      "89 / 1912\n",
      "90 / 1912\n",
      "91 / 1912\n",
      "92 / 1912\n",
      "93 / 1912\n",
      "94 / 1912\n",
      "95 / 1912\n",
      "96 / 1912\n",
      "97 / 1912\n",
      "98 / 1912\n",
      "99 / 1912\n",
      "100 / 1912\n",
      "101 / 1912\n",
      "102 / 1912\n",
      "103 / 1912\n",
      "104 / 1912\n",
      "105 / 1912\n",
      "106 / 1912\n",
      "107 / 1912\n",
      "108 / 1912\n",
      "109 / 1912\n",
      "110 / 1912\n",
      "111 / 1912\n",
      "112 / 1912\n",
      "113 / 1912\n",
      "114 / 1912\n",
      "115 / 1912\n",
      "116 / 1912\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sent_emb = []\n",
    "\n",
    "bs = 1000\n",
    "chunks = [sentences[x:x+bs] for x in range(0, len(sentences), bs)]\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"{i} / {len(chunks)}\") \n",
    "    chunk_emb = embedder.embed_batch(chunk)\n",
    "    sent_emb.extend(chunk_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(sent_emb, open(\"sent_emb.pkl\", 'wb'))\n",
    "pickle.dump(sent_index, open(\"sent_index.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = pickle.load(open(\"sent_emb.pkl\", 'rb'))\n",
    "sent_index = pickle.load(open(\"sent_index.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2embs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc_id in enumerate(sent_index):\n",
    "    doc2embs[doc_id] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc_id in enumerate(sent_index):\n",
    "    doc2embs[doc_id].append(sent_emb[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2emb = {}\n",
    "for doc_id, embs in doc2embs.items():\n",
    "    doc2emb[doc_id] = np.mean(embs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_emb = list(doc2emb.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index = list(doc2emb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(doc_emb, open(\"doc_emb.pkl\", 'wb'))\n",
    "pickle.dump(doc_index, open(\"doc_index.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_emb = pickle.load(open(\"doc_emb.pkl\", 'rb'))\n",
    "doc_index = pickle.load(open(\"doc_index.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertology",
   "language": "python",
   "name": "bertology"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
