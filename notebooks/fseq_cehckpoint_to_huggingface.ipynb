{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname\n",
    "from shutil import copyfile\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import sentencepiece as spm\n",
    "\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "from fairseq.tasks.translation import TranslationTask\n",
    "from fairseq.hub_utils import GeneratorHubInterface\n",
    "\n",
    "from transformers import WEIGHTS_NAME, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FSMTForConditionalGeneration\n",
    "from da.hugging_fseq_tokenizer import HuggingFseqTokenizer\n",
    "from da.convert_fsmt_simple_checkpoint_to_pytorch import convert_fsmt_simple_checkpoint_to_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "from da.greedy_search_interpret import greedy_search_interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = \"experiments/concat\"\n",
    "fseq_checkpoint_path = f\"{exp_path}/checkpoint_best.pt\"\n",
    "save_dir = f\"{exp_path}/hf\"\n",
    "data_path = \"data-prep/bin-data-en-et-base/\"\n",
    "spm_model_file = \"data-prep/preproc-models/syscl-en-et.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to experiments/concat/hf\n",
      "Generating experiments/concat/hf/config.json\n",
      "Generating experiments/concat/hf/pytorch_model.bin\n",
      "Generating experiments/concat/hf/vocab.txt\n",
      "Conversion is done!\n"
     ]
    }
   ],
   "source": [
    "convert_fsmt_simple_checkpoint_to_pytorch(\n",
    "    fseq_checkpoint_path, \n",
    "    save_dir, \n",
    "    data_path, \n",
    "    spm_model_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_hf = HuggingFseqTokenizer.from_pretrained(save_dir)\n",
    "model_hf = FSMTForConditionalGeneration.from_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we work on single sentences to avoid handling padding on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"i go to school every day (no).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = tokenizer_hf.encode_plus(\n",
    "    src,\n",
    "    padding=\"longest\", \n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 302,  449,    8, 4543,  668,  428,   16, 1048,  149,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i go to school every day (no).']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_hf.batch_decode(sentence['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkeypatch the function on object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf.greedy_search = MethodType(greedy_search_interpret, model_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_hf.generate(**sentence,\n",
    "                       #return_dict=True,\n",
    "                       output_hidden_states=True,\n",
    "                       output_attentions=True,\n",
    "                       do_sample=False,\n",
    "                       num_beams=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['output_ids', 'encoder_hidden_states', 'encoder_attentions', 'decoder_hidden_states', 'decoder_attentions', 'decoder_cross_attentions', 'logits'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ma k채in koolis iga p채ev (ei).']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_hf.batch_decode(res['output_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = [\"my name is Max.\", \"my name is Alex.\", \"i go to school every day (no)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer_hf.batch_encode_plus(\n",
    "    src,\n",
    "    padding=\"longest\", \n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = model_hf.generate(**batch,\n",
    "                       output_hidden_states=True,\n",
    "                       output_attentions=True,\n",
    "                       num_beams=1,\n",
    "                       do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['output_ids', 'encoder_hidden_states', 'encoder_attentions', 'decoder_hidden_states', 'decoder_attentions', 'decoder_cross_attentions', 'logits'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minu nimi on Max.<pad><pad><pad><pad>',\n",
       " 'minu nimi on Alex.<pad><pad><pad><pad>',\n",
       " 'Ma k채in koolis iga p채ev (ei)']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_hf.batch_decode(r2['output_ids'], skip_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (da)",
   "language": "python",
   "name": "da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
