{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename, dirname\n",
    "from shutil import copyfile\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "from fairseq.tasks.translation import TranslationTask\n",
    "from fairseq.hub_utils import GeneratorHubInterface\n",
    "\n",
    "from transformers import WEIGHTS_NAME, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import FSMTForConditionalGeneration\n",
    "from da.fsmt.modeling_fsmt import FSMTForConditionalGeneration\n",
    "from da.fsmt.tokenization_fsmt import FSMTTokenizer\n",
    "from da.fsmt.convert_fsmt_original_pytorch_checkpoint_to_pytorch import convert_fsmt_checkpoint_to_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "from da.greedy_search_interpret import greedy_search_interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to experiments/en_et_Europarl_ft/hf\n",
      "Generating experiments/en_et_Europarl_ft/hf/config.json\n",
      "Generating experiments/en_et_Europarl_ft/hf/pytorch_model.bin\n",
      "Generating experiments/en_et_Europarl_ft/hf/vocab.txt\n",
      "Conversion is done!\n",
      "Writing results to experiments/en_et_OpenSubtitles_ft/hf\n",
      "Generating experiments/en_et_OpenSubtitles_ft/hf/config.json\n",
      "Generating experiments/en_et_OpenSubtitles_ft/hf/pytorch_model.bin\n",
      "Generating experiments/en_et_OpenSubtitles_ft/hf/vocab.txt\n",
      "Conversion is done!\n",
      "Writing results to experiments/en_et_JRC-Acquis_ft/hf\n",
      "Generating experiments/en_et_JRC-Acquis_ft/hf/config.json\n",
      "Generating experiments/en_et_JRC-Acquis_ft/hf/pytorch_model.bin\n",
      "Generating experiments/en_et_JRC-Acquis_ft/hf/vocab.txt\n",
      "Conversion is done!\n",
      "Writing results to experiments/en_et_EMEA_ft/hf\n",
      "Generating experiments/en_et_EMEA_ft/hf/config.json\n",
      "Generating experiments/en_et_EMEA_ft/hf/pytorch_model.bin\n",
      "Generating experiments/en_et_EMEA_ft/hf/vocab.txt\n",
      "Conversion is done!\n"
     ]
    }
   ],
   "source": [
    "domain_names = [\"Europarl\", \"OpenSubtitles\", \"JRC-Acquis\", \"EMEA\"]\n",
    "\n",
    "for main_name in domain_names:\n",
    "    exp_path = f\"experiments/en_et_{main_name}_ft\"\n",
    "    fseq_checkpoint_path = f\"{exp_path}/checkpoint100.pt\"\n",
    "    save_dir = f\"{exp_path}/hf\"\n",
    "    #data_path = f\"experiments/bin-data-en-et-{main_name}/\"\n",
    "    data_path = f\"experiments/bin-data-en-et-{main_name}-ft/\"\n",
    "\n",
    "    #spm_model_file = \"data-prep/preproc-models/syscl-en-et.model\"\n",
    "    spm_model_file=None\n",
    "    \n",
    "    convert_fsmt_checkpoint_to_pytorch(\n",
    "        fseq_checkpoint_path, \n",
    "        save_dir, \n",
    "        data_path, \n",
    "        spm_model_file\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to experiments/en_et_concat60/hf\n",
      "Generating experiments/en_et_concat60/hf/config.json\n",
      "Generating experiments/en_et_concat60/hf/pytorch_model.bin\n",
      "Generating experiments/en_et_concat60/hf/vocab.txt\n",
      "Conversion is done!\n"
     ]
    }
   ],
   "source": [
    "exp_path = f\"experiments/en_et_concat60\"\n",
    "fseq_checkpoint_path = f\"{exp_path}/checkpoint60.pt\"\n",
    "save_dir = f\"{exp_path}/hf\"\n",
    "data_path = f\"experiments/bin-data-en-et-base\"\n",
    "spm_model_file=None\n",
    "\n",
    "convert_fsmt_checkpoint_to_pytorch(\n",
    "    fseq_checkpoint_path, \n",
    "    save_dir, \n",
    "    data_path, \n",
    "    spm_model_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to experiments/en_et_concat101/hf\n",
      "Generating experiments/en_et_concat101/hf/config.json\n",
      "Generating experiments/en_et_concat101/hf/pytorch_model.bin\n",
      "Generating experiments/en_et_concat101/hf/vocab.txt\n",
      "Conversion is done!\n"
     ]
    }
   ],
   "source": [
    "exp_path = f\"experiments/en_et_concat101\"\n",
    "fseq_checkpoint_path = f\"{exp_path}/checkpoint101.pt\"\n",
    "save_dir = f\"{exp_path}/hf\"\n",
    "data_path = f\"experiments/bin-data-en-et-base\"\n",
    "spm_model_file=None\n",
    "\n",
    "convert_fsmt_checkpoint_to_pytorch(\n",
    "    fseq_checkpoint_path, \n",
    "    save_dir, \n",
    "    data_path, \n",
    "    spm_model_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_hf = FSMTTokenizer.from_pretrained(save_dir) #, spm_model=f\"{save_dir}/spm_model.spm\")\n",
    "model_hf = FSMTForConditionalGeneration.from_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkeypatch the function on object\n",
    "model_hf.greedy_search = MethodType(greedy_search_interpret, model_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we work on single sentences to avoid handling padding on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"So be it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"▁So ▁be ▁it .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = tokenizer_hf.encode_plus(\n",
    "    src,\n",
    "    padding=\"longest\", \n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[690,  23,  46,   5,   2]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁So ▁be ▁it. </s>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_hf.batch_decode(sentence['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_hf.generate(**sentence,\n",
    "                       #return_dict=True,\n",
    "                       output_hidden_states=True,\n",
    "                       output_attentions=True,\n",
    "                       do_sample=False,\n",
    "                       num_beams=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2, 2858,  185,    5,    2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['output_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s> ▁Olgu ▁nii. </s>']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_hf.batch_decode(res['output_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = [\"my name is Max.\", \"my name is Alex.\", \"i go to school every day (no)\"] # should be bpe split\n",
    "\n",
    "# batch = tokenizer_hf.batch_encode_plus(\n",
    "#     src,\n",
    "#     padding=\"longest\", \n",
    "#     return_tensors=\"pt\",\n",
    "#     return_token_type_ids=False,\n",
    "#     return_attention_mask=True\n",
    "# )\n",
    "\n",
    "# r2 = model_hf.generate(**batch,\n",
    "#                        output_hidden_states=True,\n",
    "#                        output_attentions=True,\n",
    "#                        num_beams=1,\n",
    "#                        do_sample=False)\n",
    "\n",
    "# tokenizer_hf.batch_decode(r2['output_ids'], skip_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (da)",
   "language": "python",
   "name": "da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
